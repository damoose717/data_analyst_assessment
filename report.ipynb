{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team is collecting data from customers' router setups and storing them in a table titled data_analyst_assessment. At each screen of the setup process, a row is created in this table with a record of the setup step, along with various metrics. These metrics are: \n",
    "\n",
    "* Setup_id – each time a router is setup, all events tied to that setup are given this unique\n",
    "ID\n",
    "* Platform – the platform through which the router was setup\n",
    "* Type – a category for the event\n",
    "* Timestamp – the time of the event\n",
    "* Model – undefined\n",
    "* Step – the specific page in a multi-page setup process\n",
    "* Duration – the elapsed time of the setup process at that event\n",
    "* Rating – a self-reported 1-5 star rating of the setup process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this report is to identify the steps of the router setup process where customers are struggling the most, so that the team can plan and set priorities accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Walk-Through of Methodology & Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import any necessary libraries and set the parameters for viewing and plotting dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# set layout parameters \n",
    "pd.set_option('precision', 3)\n",
    "plt.style.use('fivethirtyeight')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's read in the dataframe and take a look at some of the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/dmopo/Downloads/data_analyst_assessment.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Right off the bat, we can make some observations about the data: \n",
    "\n",
    "* Platform – we see 'iOS' values, as well as some nulls\n",
    "* Type – we see 'setup_step' and 'setup_error'\n",
    "* Timestamp – the setups occurred during the month of August\n",
    "* Model – we see only one value, 'router'\n",
    "* Step – we see 'selected_account' and 'setup_start'\n",
    "* Duration – values up to 1417.937, this is likely in seconds \n",
    "* Rating – all null\n",
    "\n",
    "Let's display all of the values for each column, as well as the counts for each value. We'll ignore the 'setup_id', 'timestamp', and 'duration' columns, so that we're only looking at the categorical variables in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = list(df.columns)\n",
    "cols.remove('setup_id')\n",
    "cols.remove('timestamp')\n",
    "cols.remove('duration')\n",
    "\n",
    "for col in cols:\n",
    "    value_counts = df[col].value_counts()\n",
    "    value_counts_df = pd.DataFrame(value_counts)\n",
    "    print(value_counts_df)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see some values here that didn't show up in the previous view of the dataframe. Notably:\n",
    "\n",
    "* Platform – we see 'Android' now as well\n",
    "* Type – there are 3 values in addition to the ones we saw before \n",
    "* Model – 'router' is the only value\n",
    "* Step – a host of values denoting the step in the setup process\n",
    "* Rating – 86 non-null values\n",
    "\n",
    "Let's start digging a little deeper into the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duration Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use duration of a step as a proxy for how challenging that step was for a customer. If a customer is staying on a screen for a while, they likely are struggling with completing the tasks asked of them on that screen.\n",
    "\n",
    "Let's create a new dataframe that contains no null values for the 'duration' column. We can then make a boxplot of the duration values to get an idea of the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_df = df[df['duration'].notnull()]\n",
    "print(duration_df.shape)\n",
    "plt.boxplot(duration_df['duration'])\n",
    "plt.title('Step Duration')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e12 / 3600 / 24 / 365"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there's an outlier at over 1e12. If our assumption that this column has units of seconds is correct, this amounts to over 30,000 years. This datapoint is clearly an anomaly. Let's take a look at the row containing this point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[df['duration'] >= 1e12]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that the circle at that high outlier value is actually a cluster of circles, representing multiple datapoints, which explains why the circle border is so thick. All of the records with a ridiculously high value for 'duration' have a duration of approximately 1.6e12. Futhermore, all of these records have 'setup_error' as the step type. Let's remove these records from our dataframe and try the boxplot again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_df = df[df['duration'].notnull() & (df['type'] != 'setup_error')]\n",
    "print(duration_df.shape)\n",
    "plt.boxplot(duration_df['duration'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5e6 / 3600 / 24 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have another outlier here, with a duration at around 5 million, which is approximately 58 days. This is likely another outlier. Let's take a look at the record containing this value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duration_df[duration_df['duration'] >= 1000000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing in particular jumps out from this table. Let's remove the outlier from our dataframe and give the boxplot another try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_df = duration_df[duration_df['duration'] < 1000000]\n",
    "print(duration_df.shape)\n",
    "plt.boxplot(duration_df['duration'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "50000 / 3600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks better. We can get a better idea of the distribution. The majority of values are rather small, but the distribution has a long tail, with a few values making their way into the tens of thousands. This is feasible, as the largest value, at around 50 thousand, would be approximately 13 hours. \n",
    "\n",
    "Let's take a look at some metrics that will give us another view of the distribution -- mean, minimum, median, maximum -- grouping by setup step and sorting by mean duration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "duration_df.groupby('step').agg(\n",
    "    {'duration': ['count', 'mean', 'min', 'median', 'max']}\n",
    ").sort_values(('duration', 'mean'), ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the steps with the highest mean duration are the 'advanced_setup', 'no_internet', and 'controller_survey' steps, which it turns out are also the steps with the highest maximum duration. This makes sense, as we would expect advanced setup to be, as the name suggests, more advanced, and thus more difficult to achieve; no internet is also an issue that may require more time and pose more difficulties to resolve. Controller Survey sounds like a survey, probably when the customer gives their rating -- thus the long duration is probably due to the fact that a survey takes some time, rather than due to customers having issues. \n",
    "\n",
    "Now, let's look at another proxy for how challenging a step is: rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rating Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create a new dataframe, similar to the prior one, that contains no null values for the 'rating' column, and then let's plot it using a boxplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df = df[df['rating'].notnull()]\n",
    "print(rating_df.shape)\n",
    "plt.boxplot(rating_df['rating'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like most of the ratings are at 5, but there is at least one of each rating value from 1-5.\n",
    "\n",
    "Let's look at some aggregate measures of rating by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df.groupby('step').agg(\n",
    "    {'rating': ['count', 'mean', 'min', 'median', 'max']})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see here that the majority of the ratings are for the 'controller_survey' step. This corroborates the hypothesis made earlier that 'controller_survey' is when the customer provides their rating. Due to this hypothesis, as well as the fact that there isn't much data in any of the other steps, using rating as a proxy for level of difficulty of a step seems to be inconclusive. However, there is one other proxy we can look at."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use errors as a sign that a customer is struggling with a step. Let's create a pivot table of type versus step. Since one of the types is 'setup_error', we can take a look at which steps have both the highest raw count as well as the highest percentage of errors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_df = df.groupby(['step', 'type']).size().unstack(fill_value=0)\n",
    "error_df['error_perc'] = round(error_df['setup_error'] / \n",
    "                               (error_df['setup_step'] + error_df['setup_rating'] + error_df['setup_error'])\n",
    "                               , 3)\n",
    "error_df.sort_values(['error_perc', 'setup_error'], ascending = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the only step with a significant percentage of errors is 'setting_up', with over half of the step instances being errrors. The step with the next highest error percentage is 'setup_start', at only 8%; this step can be lumped in with setup. Only two of the other steps have any errors, and their percentages are so low they are negligible. The errors for the 'credentials' step could possibly be from entering a password incorrectly. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, the areas we recommend the team focus on are advanced setup and dealing with no internet, due to the long durations of these steps on average, as well as actually setting up the router, due to the high error rate. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
